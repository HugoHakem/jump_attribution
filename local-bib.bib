@misc{chandrasekaranJUMPCellPainting2023,
  title = {{{JUMP Cell Painting}} Dataset: Morphological Impact of 136,000 Chemical and Genetic Perturbations},
  shorttitle = {{{JUMP Cell Painting}} Dataset},
  author = {Chandrasekaran, Srinivas Niranj and Ackerman, Jeanelle and Alix, Eric and Ando, D. Michael and Arevalo, John and Bennion, Melissa and Boisseau, Nicolas and Borowa, Adriana and Boyd, Justin D. and Brino, Laurent and Byrne, Patrick J. and Ceulemans, Hugo and Ch'ng, Carolyn and Cimini, Beth A. and Clevert, Djork-Arne and Deflaux, Nicole and Doench, John G. and Dorval, Thierry and Doyonnas, Regis and Dragone, Vincenza and Engkvist, Ola and Faloon, Patrick W. and Fritchman, Briana and Fuchs, Florian and Garg, Sakshi and Gilbert, Tamara J. and Glazer, David and Gnutt, David and Goodale, Amy and Grignard, Jeremy and Guenther, Judith and Han, Yu and Hanifehlou, Zahra and Hariharan, Santosh and Hernandez, Desiree and Horman, Shane R. and Hormel, Gisela and Huntley, Michael and Icke, Ilknur and Iida, Makiyo and Jacob, Christina B. and Jaensch, Steffen and Khetan, Jawahar and {Kost-Alimova}, Maria and Krawiec, Tomasz and Kuhn, Daniel and Lardeau, Charles-Hugues and Lembke, Amanda and Lin, Francis and Little, Kevin D. and Lofstrom, Kenneth R. and Lotfi, Sofia and Logan, David J. and Luo, Yi and Madoux, Franck and Zapata, Paula A. Marin and Marion, Brittany A. and Martin, Glynn and McCarthy, Nicola Jane and Mervin, Lewis and Miller, Lisa and Mohamed, Haseeb and Monteverde, Tiziana and Mouchet, Elizabeth and Nicke, Barbara and Ogier, Arnaud and Ong, Anne-Laure and Osterland, Marc and Otrocka, Magdalena and Peeters, Pieter J. and Pilling, James and Prechtl, Stefan and Qian, Chen and Rataj, Krzysztof and Root, David E. and Sakata, Sylvie K. and Scrace, Simon and Shimizu, Hajime and Simon, David and Sommer, Peter and Spruiell, Craig and Sumia, Iffat and Swalley, Susanne E. and Terauchi, Hiroki and Thibaudeau, Amandine and Unruh, Amy and de Waeter, Jelle Van and Dyck, Michiel Van and van Staden, Carlo and Warcho{\l}, Micha{\l} and Weisbart, Erin and Weiss, Am{\'e}lie and {Wiest-Daessle}, Nicolas and Williams, Guy and Yu, Shan and Zapiec, Bolek and {\.Z}y{\l}a, Marek and Singh, Shantanu and Carpenter, Anne E.},
  year = {2023},
  month = mar,
  primaryclass = {New Results},
  pages = {2023.03.23.534023},
  publisher = {bioRxiv},
  doi = {10.1101/2023.03.23.534023},
  urldate = {2023-11-19},
  abstract = {Image-based profiling has emerged as a powerful technology for various steps in basic biological and pharmaceutical discovery, but the community has lacked a large, public reference set of data from chemical and genetic perturbations. Here we present data generated by the Joint Undertaking for Morphological Profiling (JUMP)-Cell Painting Consortium, a collaboration between 10 pharmaceutical companies, six supporting technology companies, and two non-profit partners. When completed, the dataset will contain images and profiles from the Cell Painting assay for over 116,750 unique compounds, over-expression of 12,602 genes, and knockout of 7,975 genes using CRISPR-Cas9, all in human osteosarcoma cells (U2OS). The dataset is estimated to be 115 TB in size and capturing 1.6 billion cells and their single-cell profiles. File quality control and upload is underway and will be completed over the coming months at the Cell Painting Gallery: https://registry.opendata.aws/cellpainting-gallery. A portal to visualize a subset of the data is available at https://phenaid.ardigen.com/jumpcpexplorer/.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/JJ7CXXAJ/Chandrasekaran et al. - 2023 - JUMP Cell Painting dataset morphological impact o.pdf}
}

@article{chandrasekaranImagebasedProfilingDrug2021a,
  title = {Image-Based Profiling for Drug Discovery: Due for a Machine-Learning Upgrade?},
  shorttitle = {Image-Based Profiling for Drug Discovery},
  author = {Chandrasekaran, Srinivas Niranj and Ceulemans, Hugo and Boyd, Justin D. and Carpenter, Anne E.},
  year = {2021},
  month = feb,
  journal = {Nature Reviews Drug Discovery},
  volume = {20},
  number = {2},
  pages = {145--159},
  issn = {1474-1776, 1474-1784},
  doi = {10.1038/s41573-020-00117-w},
  urldate = {2023-08-17},
  abstract = {Image-b ased profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-b ased features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-a ssociated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-b ased information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/KTGUPELC/Chandrasekaran et al. - 2021 - Image-based profiling for drug discovery due for .pdf}
}

@article{kalininVersatileInformationRetrieval2024,
  title = {A Versatile Information Retrieval Framework for Evaluating Profile Strength and Similarity},
  author = {Kalinin, Alexandr A. and Arevalo, John and Vulliard, Loan and Serrano, Erik and Tsang, Hillary and Bornholdt, Michael and Rajwa, Bartek and Carpenter, Anne E. and Way, Gregory P. and Singh, Shantanu},
  year = {2024},
  month = apr,
  journal = {bioRxiv},
  pages = {2024.04.01.587631},
  doi = {10.1101/2024.04.01.587631},
  urldate = {2024-06-06},
  abstract = {In profiling assays, thousands of biological properties are measured in a single test, yielding biological discoveries by capturing the state of a cell population, often at the single-cell level. However, for profiling datasets, it has been challenging to evaluate the phenotypic activity of a sample and the phenotypic consistency among samples, due to profiles' high dimensionality, heterogeneous nature, and non-linear properties. Existing methods leave researchers uncertain where to draw boundaries between meaningful biological response and technical noise. Here, we developed a statistical framework that uses the well-established mean average precision (mAP) as a single, data-driven metric to bridge this gap. We validated the mAP framework against established metrics through simulations and real-world data applications, revealing its ability to capture subtle and meaningful biological differences in cell state. Specifically, we used mAP to assess both phenotypic activity for a given perturbation (or a sample) as well as consistency within groups of perturbations (or samples) across diverse high-dimensional datasets. We evaluated the framework on different profile types (image, protein, and mRNA profiles), perturbation types (CRISPR gene editing, gene overexpression, and small molecules), and profile resolutions (single-cell and bulk). Our open-source software allows this framework to be applied to identify interesting biological phenomena and promising therapeutics from large-scale profiling data.},
  pmcid = {PMC11014546},
  pmid = {38617315},
  file = {/Users/amunozgo/Zotero/storage/27QHNCPB/Kalinin et al. - 2024 - A versatile information retrieval framework for ev.pdf}
}

@misc{ecksteinDiscriminativeAttributionCounterfactuals2021,
  title = {Discriminative {{Attribution}} from {{Counterfactuals}}},
  author = {Eckstein, Nils and Bates, Alexander S. and Jefferis, Gregory S. X. E. and Funke, Jan},
  year = {2021},
  month = sep,
  number = {arXiv:2109.13412},
  eprint = {2109.13412},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2109.13412},
  urldate = {2023-08-17},
  abstract = {We present a method for neural network interpretability by combining feature attribution with counterfactual explanations to generate attribution maps that highlight the most discriminative features between pairs of classes. We show that this method can be used to quantitatively evaluate the performance of feature attribution methods in an objective manner, thus preventing potential observer bias. We evaluate the proposed method on three diverse datasets, including a challenging artificial dataset and real-world biological data. We show quantitatively and qualitatively that the highlighted features are substantially more discriminative than those extracted using conventional attribution methods and argue that this type of explanation is better suited for understanding fine grained class differences as learned by a deep neural network.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/amunozgo/Zotero/storage/DP2VZMFP/Eckstein et al. - 2021 - Discriminative Attribution from Counterfactuals.pdf;/Users/amunozgo/Zotero/storage/XXBAD5NE/2109.html}
}

@article{lamiableRevealingInvisibleCell2023,
  title = {Revealing Invisible Cell Phenotypes with Conditional Generative Modeling},
  author = {Lamiable, Alexis and Champetier, Tiphaine and Leonardi, Francesco and Cohen, Ethan and Sommer, Peter and Hardy, David and Argy, Nicolas and Massougbodji, Achille and Del Nery, Elaine and Cottrell, Gilles and Kwon, Yong-Jun and Genovesio, Auguste},
  year = {2023},
  month = oct,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {6386},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-42124-6},
  urldate = {2024-06-06},
  abstract = {Biological sciences, drug discovery and medicine rely heavily on cell phenotype perturbation and microscope observation. However, most cellular phenotypic changes are subtle and thus hidden from us by natural cell variability: two cells in the same condition already look different. In this study, we show that conditional generative models can be used to transform an image of cells from any one condition to another, thus canceling cell variability. We visually and quantitatively validate that the principle of synthetic cell perturbation works on discernible cases. We then illustrate its effectiveness in displaying otherwise invisible cell phenotypes triggered by blood cells under parasite infection, or by the presence of a disease-causing pathological mutation in differentiated neurons derived from iPSCs, or by low concentration drug treatments. The proposed approach, easy to use and robust, opens the door to more accessible discovery of biological and disease biomarkers.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Biomarkers,Cellular imaging,Image processing,Organelles},
  file = {/Users/amunozgo/Zotero/storage/HPMVJKSR/Lamiable et al. - 2023 - Revealing invisible cell phenotypes with condition.pdf}
}

@inproceedings{zhuUnpairedImageToImageTranslation2017,
  title = {Unpaired {{Image-To-Image Translation Using Cycle-Consistent Adversarial Networks}}},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  year = {2017},
  pages = {2223--2232},
  urldate = {2023-08-21},
  file = {/Users/amunozgo/Zotero/storage/5IMT3QCZ/Zhu et al. - 2017 - Unpaired Image-To-Image Translation Using Cycle-Co.pdf}
}

