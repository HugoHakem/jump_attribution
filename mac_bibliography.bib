@article{andradeUpdatedCatalogueHomologues1998,
  title = {Updated Catalogue of Homologues to Human Disease-Related Proteins in the Yeast Genome 1},
  author = {Andrade, Miguel A and Sander, Chris and Valencia, Alfonso},
  year = {1998},
  journal = {FEBS Letters},
  volume = {426},
  number = {1},
  pages = {7--16},
  issn = {1873-3468},
  doi = {10.1016/S0014-5793(98)00277-4},
  urldate = {2023-11-29},
  abstract = {The recent availability of the full Saccharomyces cerevisiae genome offers a perfect opportunity for revising the number of homologues to human disease-related proteins. We carried out automatic analysis of the complete S. cerevisiae genome and of the set of human disease-related proteins as identified in the SwissProt sequence data base. We identified 285 yeast proteins similar to 155 human disease-related proteins, including 239 possible cases of human-yeast direct functional equivalence (orthology). Of these, 40 cases are suggested as new, previously undiscovered relationships. Four of them are particularly interesting, since the yeast sequence is the most phylogenetically distant member of the protein family, including proteins related to diseases such as phenylketonuria, lupus erythematosus, Norum and fish eye disease and Wiskott-Aldrich syndrome.},
  langid = {english},
  keywords = {aa,amino acids,Function prediction,GBD,GTPase binding domain,HDRP,Human disease,human disease-related protein,Sequence analysis,small nuclear ribonucleoproteins,snRNP,WAS,WAS homology,WH,Wiskott-Aldrich syndrome,Yeast genome},
  file = {/Users/amunozgo/Zotero/storage/85J5JXN8/Andrade et al. - 1998 - Updated catalogue of homologues to human disease-r.pdf;/Users/amunozgo/Zotero/storage/7EKVKXNB/S0014-5793(98)00277-4.html}
}

@misc{AppointmentBooking,
  title = {Appointment {{Booking}}},
  urldate = {2024-02-20},
  howpublished = {https://www.patientsreach.com/schedule/camberville/patient\_types/new/visit\_types/1/providers/20/chair/16/appointment\_id/gAAAAABl1NagC56zhS\_raes6grqK1UwaZBE5ifNeaipAhOB7KV\_6t9YSwfnJeySc9LT7quoJ11HuUdgzibI1ULPwTMOI9HqQ3w==?patient\_exist=false},
  file = {/Users/amunozgo/Zotero/storage/JFYXNIZN/gAAAAABl1NagC56zhS_raes6grqK1UwaZBE5ifNeaipAhOB7KV_6t9YSwfnJeySc9LT7quoJ11HuUdgzibI1ULPwTMOI9Hq.html}
}

@article{architSegmentAnythingMicroscopy,
  title = {Segment {{Anything}} for {{Microscopy}}},
  author = {Archit, Anwai and Nair, Sushmita and Khalid, Nabeel and Hilt, Paul and Rajashekar, Vikas and Freitag, Marei and Gupta, Sagnik and Dengel, Andreas and Ahmed, Sheraz and Pape, Constantin},
  abstract = {We present Segment Anything for Microscopy, a tool for interactive and automatic segmentation and tracking of objects in multi-dimensional microscopy data. Our method is based on Segment Anything, a vision foundation model for image segmentation. We extend it by training specialized models for microscopy data that significantly improve segmentation quality for a wide range of imaging conditions. We also implement annotation tools for interactive (volumetric) segmentation and tracking, that speed up data annotation significantly compared to established tools. Our work constitutes the first application of vision foundation models to microscopy, laying the groundwork for solving image analysis problems in these domains with a small set of powerful deep learning architectures.},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/LKVWTDRA/Archit et al. - Segment Anything for Microscopy.pdf}
}

@article{arevaloEvaluatingBatchCorrection2023,
  title = {Evaluating Batch Correction Methods for Image-Based Cell Profiling},
  author = {Arevalo, John and {van Dijk}, Robert and Carpenter, Anne E. and Singh, Shantanu},
  year = {2023},
  month = sep,
  journal = {bioRxiv},
  pages = {2023.09.15.558001},
  doi = {10.1101/2023.09.15.558001},
  urldate = {2024-02-01},
  abstract = {High-throughput image-based profiling platforms are powerful technologies capable of collecting data from billions of cells exposed to thousands perturbations in a time- and cost-effective manner. Therefore, image-based profiling data has been increasingly used for diverse biological applications, such as predicting drug mechanism of action or gene function. However, batch effects pose severe limitations to community-wide efforts to integrate and interpret image-based profiling data collected across different laboratories and equipment. To address this problem, we evaluated seven top-ranked batch correction strategies for mRNA profiles in the context of a newly released Cell Painting dataset, the largest publicly accessible image-based dataset. We focused on five different use scenarios with varying complexity, and found that Harmony, a nonlinear method, consistently outperformed the other tested methods. Furthermore, we provide a framework, benchmark, and metrics for the future assessment of new batch correction methods. Overall, this work paves the way for improvements that allow the community to make best use of public Cell Painting data for scientific discovery.},
  pmcid = {PMC10516049},
  pmid = {37745478},
  file = {/Users/amunozgo/Zotero/storage/GWZU7VBQ/Arevalo et al. - 2023 - Evaluating batch correction methods for image-base.pdf}
}

@article{botsteinYeastExperimentalOrganism2011,
  title = {Yeast: {{An Experimental Organism}} for 21st {{Century Biology}}},
  shorttitle = {Yeast},
  author = {Botstein, David and Fink, Gerald R.},
  year = {2011},
  month = nov,
  journal = {Genetics},
  volume = {189},
  number = {3},
  pages = {695--704},
  issn = {0016-6731},
  doi = {10.1534/genetics.111.130765},
  urldate = {2023-12-11},
  abstract = {In this essay, we revisit the status of yeast as a model system for biology. We first summarize important contributions of yeast to eukaryotic biology that we anticipated in 1988 in our first article on the subject. We then describe transformative developments that we did not anticipate, most of which followed the publication of the complete genomic sequence of Saccharomyces cerevisiae in 1996. In the intervening 23 years it appears to us that yeast has graduated from a position as the premier model for eukaryotic cell biology to become the pioneer organism that has facilitated the establishment of the entirely new fields of study called ``functional genomics'' and ``systems biology.'' These new fields look beyond the functions of individual genes and proteins, focusing on how these interact and work together to determine the properties of living cells and organisms.},
  pmcid = {PMC3213361},
  pmid = {22084421},
  file = {/Users/amunozgo/Zotero/storage/3SNJPUME/Botstein and Fink - 2011 - Yeast An Experimental Organism for 21st Century B.pdf}
}

@article{brayCellPaintingHighcontent2016,
  title = {Cell {{Painting}}, a High-Content Image-Based Assay for Morphological Profiling Using Multiplexed Fluorescent Dyes},
  author = {Bray, Mark-Anthony and Singh, Shantanu and Han, Han and Davis, Chadwick T. and Borgeson, Blake and Hartland, Cathy and {Kost-Alimova}, Maria and Gustafsdottir, Sigrun M. and Gibson, Christopher C. and Carpenter, Anne E.},
  year = {2016},
  month = sep,
  journal = {Nature Protocols},
  volume = {11},
  number = {9},
  pages = {1757--1774},
  publisher = {Nature Publishing Group},
  issn = {1750-2799},
  doi = {10.1038/nprot.2016.105},
  urldate = {2023-08-30},
  abstract = {Cell Painting is a high-content screening assay that uses multiplexed fluorescent dyes for image-based profiling of {$\sim$}1,500 morphological features. Image analysis with CellProfiler automatically identifies and extracts data from individual cells.},
  copyright = {2016 Springer Nature Limited},
  langid = {english},
  keywords = {Fluorescence imaging,High-throughput screening,Image processing,Phenotypic screening},
  file = {/Users/amunozgo/Zotero/storage/XNIWLXI5/Bray et al. - 2016 - Cell Painting, a high-content image-based assay fo.pdf}
}

@article{chandrasekaranImagebasedProfilingDrug2021,
  title = {Image-Based Profiling for Drug Discovery: Due for a Machine-Learning Upgrade?},
  shorttitle = {Image-Based Profiling for Drug Discovery},
  author = {Chandrasekaran, Srinivas Niranj and Ceulemans, Hugo and Boyd, Justin D. and Carpenter, Anne E.},
  year = {2021},
  month = feb,
  journal = {Nature Reviews Drug Discovery},
  volume = {20},
  number = {2},
  pages = {145--159},
  publisher = {Nature Publishing Group},
  issn = {1474-1784},
  doi = {10.1038/s41573-020-00117-w},
  urldate = {2023-08-17},
  abstract = {Image-based profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-based features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-associated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-based information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Phenotypic screening},
  file = {/Users/amunozgo/Zotero/storage/X7FTDWFV/Chandrasekaran et al. - 2021 - Image-based profiling for drug discovery due for .pdf}
}

@article{chandrasekaranImagebasedProfilingDrug2021a,
  title = {Image-Based Profiling for Drug Discovery: Due for a Machine-Learning Upgrade?},
  shorttitle = {Image-Based Profiling for Drug Discovery},
  author = {Chandrasekaran, Srinivas Niranj and Ceulemans, Hugo and Boyd, Justin D. and Carpenter, Anne E.},
  year = {2021},
  month = feb,
  journal = {Nature Reviews Drug Discovery},
  volume = {20},
  number = {2},
  pages = {145--159},
  issn = {1474-1776, 1474-1784},
  doi = {10.1038/s41573-020-00117-w},
  urldate = {2023-08-17},
  abstract = {Image-b ased profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-b ased features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-a ssociated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-b ased information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/KTGUPELC/Chandrasekaran et al. - 2021 - Image-based profiling for drug discovery due for .pdf}
}

@article{chandrasekaranImagebasedProfilingDrug2021b,
  title = {Image-Based Profiling for Drug Discovery: Due for a Machine-Learning Upgrade?},
  shorttitle = {Image-Based Profiling for Drug Discovery},
  author = {Chandrasekaran, Srinivas Niranj and Ceulemans, Hugo and Boyd, Justin D. and Carpenter, Anne E.},
  year = {2021},
  month = feb,
  journal = {Nature Reviews Drug Discovery},
  volume = {20},
  number = {2},
  pages = {145--159},
  publisher = {Nature Publishing Group},
  issn = {1474-1784},
  doi = {10.1038/s41573-020-00117-w},
  urldate = {2023-11-19},
  abstract = {Image-based profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-based features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-associated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-based information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Phenotypic screening}
}

@article{chandrasekaranImagebasedProfilingDrug2021c,
  title = {Image-Based Profiling for Drug Discovery: Due for a Machine-Learning Upgrade?},
  shorttitle = {Image-Based Profiling for Drug Discovery},
  author = {Chandrasekaran, Srinivas Niranj and Ceulemans, Hugo and Boyd, Justin D. and Carpenter, Anne E.},
  year = {2021},
  month = feb,
  journal = {Nature Reviews Drug Discovery},
  volume = {20},
  number = {2},
  pages = {145--159},
  publisher = {Nature Publishing Group},
  issn = {1474-1784},
  doi = {10.1038/s41573-020-00117-w},
  urldate = {2024-02-01},
  abstract = {Image-based profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-based features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-associated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-based information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Phenotypic screening},
  file = {/Users/amunozgo/Zotero/storage/YMRTFLH5/Chandrasekaran et al. - 2021 - Image-based profiling for drug discovery due for .pdf}
}

@article{chandrasekaranImagebasedProfilingDrug2021d,
  title = {Image-Based Profiling for Drug Discovery: Due for a Machine-Learning Upgrade?},
  shorttitle = {Image-Based Profiling for Drug Discovery},
  author = {Chandrasekaran, Srinivas Niranj and Ceulemans, Hugo and Boyd, Justin D. and Carpenter, Anne E.},
  year = {2021},
  month = feb,
  journal = {Nature Reviews Drug Discovery},
  volume = {20},
  number = {2},
  pages = {145--159},
  publisher = {Nature Publishing Group},
  issn = {1474-1784},
  doi = {10.1038/s41573-020-00117-w},
  urldate = {2024-06-06},
  abstract = {Image-based profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-based features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-associated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-based information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Phenotypic screening},
  file = {/Users/amunozgo/Zotero/storage/FDTMQJNQ/Chandrasekaran et al. - 2021 - Image-based profiling for drug discovery due for .pdf}
}

@misc{chandrasekaranJUMPCellPainting2023,
  title = {{{JUMP Cell Painting}} Dataset: Morphological Impact of 136,000 Chemical and Genetic Perturbations},
  shorttitle = {{{JUMP Cell Painting}} Dataset},
  author = {Chandrasekaran, Srinivas Niranj and Ackerman, Jeanelle and Alix, Eric and Ando, D. Michael and Arevalo, John and Bennion, Melissa and Boisseau, Nicolas and Borowa, Adriana and Boyd, Justin D. and Brino, Laurent and Byrne, Patrick J. and Ceulemans, Hugo and Ch'ng, Carolyn and Cimini, Beth A. and Clevert, Djork-Arne and Deflaux, Nicole and Doench, John G. and Dorval, Thierry and Doyonnas, Regis and Dragone, Vincenza and Engkvist, Ola and Faloon, Patrick W. and Fritchman, Briana and Fuchs, Florian and Garg, Sakshi and Gilbert, Tamara J. and Glazer, David and Gnutt, David and Goodale, Amy and Grignard, Jeremy and Guenther, Judith and Han, Yu and Hanifehlou, Zahra and Hariharan, Santosh and Hernandez, Desiree and Horman, Shane R. and Hormel, Gisela and Huntley, Michael and Icke, Ilknur and Iida, Makiyo and Jacob, Christina B. and Jaensch, Steffen and Khetan, Jawahar and {Kost-Alimova}, Maria and Krawiec, Tomasz and Kuhn, Daniel and Lardeau, Charles-Hugues and Lembke, Amanda and Lin, Francis and Little, Kevin D. and Lofstrom, Kenneth R. and Lotfi, Sofia and Logan, David J. and Luo, Yi and Madoux, Franck and Zapata, Paula A. Marin and Marion, Brittany A. and Martin, Glynn and McCarthy, Nicola Jane and Mervin, Lewis and Miller, Lisa and Mohamed, Haseeb and Monteverde, Tiziana and Mouchet, Elizabeth and Nicke, Barbara and Ogier, Arnaud and Ong, Anne-Laure and Osterland, Marc and Otrocka, Magdalena and Peeters, Pieter J. and Pilling, James and Prechtl, Stefan and Qian, Chen and Rataj, Krzysztof and Root, David E. and Sakata, Sylvie K. and Scrace, Simon and Shimizu, Hajime and Simon, David and Sommer, Peter and Spruiell, Craig and Sumia, Iffat and Swalley, Susanne E. and Terauchi, Hiroki and Thibaudeau, Amandine and Unruh, Amy and de Waeter, Jelle Van and Dyck, Michiel Van and van Staden, Carlo and Warcho{\l}, Micha{\l} and Weisbart, Erin and Weiss, Am{\'e}lie and {Wiest-Daessle}, Nicolas and Williams, Guy and Yu, Shan and Zapiec, Bolek and {\.Z}y{\l}a, Marek and Singh, Shantanu and Carpenter, Anne E.},
  year = {2023},
  month = mar,
  primaryclass = {New Results},
  pages = {2023.03.23.534023},
  publisher = {bioRxiv},
  doi = {10.1101/2023.03.23.534023},
  urldate = {2023-11-19},
  abstract = {Image-based profiling has emerged as a powerful technology for various steps in basic biological and pharmaceutical discovery, but the community has lacked a large, public reference set of data from chemical and genetic perturbations. Here we present data generated by the Joint Undertaking for Morphological Profiling (JUMP)-Cell Painting Consortium, a collaboration between 10 pharmaceutical companies, six supporting technology companies, and two non-profit partners. When completed, the dataset will contain images and profiles from the Cell Painting assay for over 116,750 unique compounds, over-expression of 12,602 genes, and knockout of 7,975 genes using CRISPR-Cas9, all in human osteosarcoma cells (U2OS). The dataset is estimated to be 115 TB in size and capturing 1.6 billion cells and their single-cell profiles. File quality control and upload is underway and will be completed over the coming months at the Cell Painting Gallery: https://registry.opendata.aws/cellpainting-gallery. A portal to visualize a subset of the data is available at https://phenaid.ardigen.com/jumpcpexplorer/.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/JJ7CXXAJ/Chandrasekaran et al. - 2023 - JUMP Cell Painting dataset morphological impact o.pdf}
}

@article{cottetLiveCellPainting2023,
  title = {Live {{Cell Painting}}: {{New}} Nontoxic Dye to Probe Cell Physiology in High Content Screening},
  shorttitle = {Live {{Cell Painting}}},
  author = {Cottet, Martin and Marrero, Yuniel Fernandez and Mathien, Simon and Audette, Karine and Lambert, Raphaelle and Bonneil, Eric and Chng, Kenneth and Campos, Alex and Andrews, David W.},
  year = {2023},
  month = oct,
  journal = {SLAS Discovery},
  volume = {0},
  number = {0},
  publisher = {Elsevier},
  issn = {2472-5552, 2472-5560},
  doi = {10.1016/j.slasd.2023.10.005},
  urldate = {2023-10-31},
  langid = {english},
  keywords = {Automation,ChromaLive,Drug Discovery,High Content Screening,Live cell imaging,Live Cell Painting,Phenotypic profiling,Phenotypic screen},
  file = {/Users/amunozgo/Zotero/storage/M66NE8LQ/Cottet et al. - 2023 - Live Cell Painting New nontoxic dye to probe cell.pdf}
}

@article{cottetLiveCellPainting2023a,
  title = {Live Cell Painting: {{New}} Nontoxic Dye to Probe Cell Physiology in High Content Screening},
  shorttitle = {Live Cell Painting},
  author = {Cottet, Martin and Marrero, Yuniel Fernandez and Mathien, Simon and Audette, Karine and Lambert, Raphaelle and Bonneil, Eric and Chng, Kenneth and Campos, Alex and Andrews, David W.},
  year = {2023},
  month = oct,
  journal = {SLAS Discovery},
  volume = {0},
  number = {0},
  publisher = {Elsevier},
  issn = {2472-5552, 2472-5560},
  doi = {10.1016/j.slasd.2023.10.005},
  urldate = {2023-11-19},
  langid = {english},
  keywords = {Automation,ChromaLive,Drug discovery,High content screening,Live cell imaging,Live cell painting,Phenotypic profiling,Phenotypic screen},
  file = {/Users/amunozgo/Zotero/storage/5CJT6MQ4/Cottet et al. - 2023 - Live cell painting New nontoxic dye to probe cell.pdf}
}

@misc{ecksteinDiscriminativeAttributionCounterfactuals2021,
  title = {Discriminative {{Attribution}} from {{Counterfactuals}}},
  author = {Eckstein, Nils and Bates, Alexander S. and Jefferis, Gregory S. X. E. and Funke, Jan},
  year = {2021},
  month = sep,
  number = {arXiv:2109.13412},
  eprint = {2109.13412},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2109.13412},
  urldate = {2023-08-17},
  abstract = {We present a method for neural network interpretability by combining feature attribution with counterfactual explanations to generate attribution maps that highlight the most discriminative features between pairs of classes. We show that this method can be used to quantitatively evaluate the performance of feature attribution methods in an objective manner, thus preventing potential observer bias. We evaluate the proposed method on three diverse datasets, including a challenging artificial dataset and real-world biological data. We show quantitatively and qualitatively that the highlighted features are substantially more discriminative than those extracted using conventional attribution methods and argue that this type of explanation is better suited for understanding fine grained class differences as learned by a deep neural network.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/amunozgo/Zotero/storage/DP2VZMFP/Eckstein et al. - 2021 - Discriminative Attribution from Counterfactuals.pdf;/Users/amunozgo/Zotero/storage/XXBAD5NE/2109.html}
}

@article{FigImagebasedProfiling,
  title = {Fig. 1: {{Image-based}} Profiling. {\textbar} {{Nature Reviews Drug Discovery}}},
  shorttitle = {Fig. 1},
  urldate = {2023-11-19},
  langid = {english}
}

@inproceedings{funkeCandidateMulticutCell2018,
  title = {The Candidate Multi-Cut for Cell Segmentation},
  booktitle = {2018 {{IEEE}} 15th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}} 2018)},
  author = {Funke, Jan and Zhang, Chong and Pietzsch, Tobias and Gonzalez Ballester, Miguel A. and Saalfeld, Stephan},
  year = {2018},
  month = apr,
  pages = {649--653},
  publisher = {IEEE},
  address = {Washington, DC},
  doi = {10.1109/ISBI.2018.8363658},
  urldate = {2023-08-11},
  isbn = {978-1-5386-3636-7},
  file = {/Users/amunozgo/Zotero/storage/XXWVUFZA/Funke et al. - 2018 - The candidate multi-cut for cell segmentation.pdf}
}

@article{garcia-fossaInterpretingImageBased2023,
  title = {Interpreting {{Image}}-based {{Profiles}} Using {{Similarity Clustering}} and {{Single}}-{{Cell Visualization}}},
  author = {Garcia-Fossa, Fernanda and Cruz, Mario Costa and Haghighi, Marzieh and De Jesus, Marcelo Bispo and Singh, Shantanu and Carpenter, Anne E. and Cimini, Beth A.},
  year = {2023},
  month = mar,
  journal = {Current Protocols},
  volume = {3},
  number = {3},
  pages = {e713},
  issn = {2691-1299, 2691-1299},
  doi = {10.1002/cpz1.713},
  urldate = {2023-08-17},
  abstract = {Image-based profiling quantitatively assesses the effects of perturbations on cells by capturing a breadth of changes via microscopy. Here we provide two complementary protocols to help explore and interpret data from image-based profiling experiments. In the first protocol, we examine the similarity among perturbed cell samples using data from compounds that cluster by their mechanism of action (MOAs). The protocol includes steps to examine feature-driving differences between samples and how to visualize correlations between features and treatments to create interpretable heatmaps using an open-source web tool, Morpheus. In the second protocol, we show how to interactively explore images together with the numerical data, while we provide scripts to create visualizations of representative single cells and image sites to understand how changes in features are reflected in the images. Together, these two tutorials help biologists and researchers interpret their image-based data to speed up research.},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/Y734WVMK/Garcia‐Fossa et al. - 2023 - Interpreting Image‐based Profiles using Similarity.pdf}
}

@article{gogoberidzePredictiveMaintenanceInternet,
  title = {Predictive {{Maintenance}} in the {{Internet}} of {{Things}}: {{Survival Analysis}} and {{Deep}}},
  author = {Gogoberidze, Nodari},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/FH7M9XJK/Gogoberidze - Predictive Maintenance in the Internet of Things .pdf}
}

@article{harrisonEvaluatingUtilityBrightfield2023,
  title = {Evaluating the Utility of Brightfield Image Data for Mechanism of Action Prediction},
  author = {Harrison, Philip John and Gupta, Ankit and Rietdijk, Jonne and Wieslander, H{\aa}kan and {Carreras-Puigvert}, Jordi and Georgiev, Polina and W{\"a}hlby, Carolina and Spjuth, Ola and Sintorn, Ida-Maria},
  year = {2023},
  month = jul,
  journal = {PLOS Computational Biology},
  volume = {19},
  number = {7},
  pages = {e1011323},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1011323},
  urldate = {2023-08-24},
  abstract = {Fluorescence staining techniques, such as Cell Painting, together with fluorescence microscopy have proven invaluable for visualizing and quantifying the effects that drugs and other perturbations have on cultured cells. However, fluorescence microscopy is expensive, time-consuming, labor-intensive, and the stains applied can be cytotoxic, interfering with the activity under study. The simplest form of microscopy, brightfield microscopy, lacks these downsides, but the images produced have low contrast and the cellular compartments are difficult to discern. Nevertheless, by harnessing deep learning, these brightfield images may still be sufficient for various predictive purposes. In this study, we compared the predictive performance of models trained on fluorescence images to those trained on brightfield images for predicting the mechanism of action (MoA) of different drugs. We also extracted CellProfiler features from the fluorescence images and used them to benchmark the performance. Overall, we found comparable and largely correlated predictive performance for the two imaging modalities. This is promising for future studies of MoAs in time-lapse experiments for which using fluorescence images is problematic. Explorations based on explainable AI techniques also provided valuable insights regarding compounds that were better predicted by one modality over the other.},
  langid = {english},
  keywords = {Bright field microscopy,Cell staining,Deep learning,Fluorescence imaging,Fluorescence microscopy,Fluorescent dyes,Learning,Neural networks},
  file = {/Users/amunozgo/Zotero/storage/8AZ3FZNR/Harrison et al. - 2023 - Evaluating the utility of brightfield image data f.pdf}
}

@misc{hirschTrackingWeaklysupervisedLearning2022,
  title = {Tracking by Weakly-Supervised Learning and Graph Optimization for Whole-Embryo {{C}}. Elegans Lineages},
  author = {Hirsch, Peter and {Malin-Mayor}, Caroline and Santella, Anthony and Preibisch, Stephan and Kainmueller, Dagmar and Funke, Jan},
  year = {2022},
  month = aug,
  number = {arXiv:2208.11467},
  eprint = {2208.11467},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.11467},
  urldate = {2023-08-11},
  abstract = {Tracking all nuclei of an embryo in noisy and dense fluorescence microscopy data is a challenging task. We build upon a recent method for nuclei tracking that combines weakly-supervised learning from a small set of nuclei center point annotations with an integer linear program (ILP) for optimal cell lineage extraction. Our work specifically addresses the following challenging properties of C. elegans embryo recordings: (1) Many cell divisions as compared to benchmark recordings of other organisms, and (2) the presence of polar bodies that are easily mistaken as cell nuclei. To cope with (1), we devise and incorporate a learnt cell division detector. To cope with (2), we employ a learnt polar body detector. We further propose automated ILP weights tuning via a structured SVM, alleviating the need for tedious manual set-up of a respective grid search. Our method outperforms the previous leader of the cell tracking challenge on the Fluo-N3DH-CE embryo dataset. We report a further extensive quantitative evaluation on two more C. elegans datasets. We will make these datasets public to serve as an extended benchmark for future method development. Our results suggest considerable improvements yielded by our method, especially in terms of the correctness of division event detection and the number and length of fully correct track segments. Code: https://github.com/funkelab/linajea},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/amunozgo/Zotero/storage/M796CM4H/Hirsch et al. - 2022 - Tracking by weakly-supervised learning and graph o.pdf;/Users/amunozgo/Zotero/storage/MAQQMLIC/2208.html}
}

@misc{InpaintingNetworksLearn,
  title = {Inpainting {{Networks Learn}} to {{Separate Cells}} in {{Microscopy Images}} {\textbar} {{Janelia Research Campus}}},
  urldate = {2023-08-11},
  howpublished = {https://www.janelia.org/publication/inpainting-networks-learn-to-separate-cells-in-microscopy-images},
  file = {/Users/amunozgo/Zotero/storage/83RWU4MH/inpainting-networks-learn-to-separate-cells-in-microscopy-images.html}
}

@misc{jax2018github,
  title = {{{JAX}}: Composable Transformations of {{Python}}+{{NumPy}} Programs},
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and {Wanderman-Milne}, Skye and Zhang, Qiao},
  year = {2018}
}

@article{jiCP2ImageGeneratingHighquality,
  title = {{{CP2Image}}: {{Generating}} High-Quality Single-Cell Images Using {{CellProfiler}} Representations},
  author = {Ji, Yanni and Cutiongco, Marie F A},
  abstract = {Single-cell high-throughput microscopy images contain key biological information underlying normal and pathological cellular processes. Image-based analysis and profiling are powerful and promising for extracting this information but are made difficult due to substantial complexity and heterogeneity in cellular phenotype. Hand-crafted methods and machine learning models are popular ways to extract cell image information. Representations extracted via machine learning models, which often exhibit good reconstruction performance, lack biological interpretability. Hand-crafted representations, on the contrary, have clear biological meanings and thus are interpretable. Whether these hand-crafted representations can also generate realistic images is not clear. In this paper, we propose a CellProfiler to image (CP2Image) model that can directly generate realistic cell images from CellProfiler representations. We also demonstrate most biological information encoded in the CellProfiler representations is well-preserved in the generating process. This is the first time hand-crafted representations be shown to have the generative ability and provide researchers with an intuitive way for their further analysis.},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/S3STLVKD/Ji and Cutiongco - CP2Image Generating high-quality single-cell imag.pdf}
}

@article{kalininVersatileInformationRetrieval2024,
  title = {A Versatile Information Retrieval Framework for Evaluating Profile Strength and Similarity},
  author = {Kalinin, Alexandr A. and Arevalo, John and Vulliard, Loan and Serrano, Erik and Tsang, Hillary and Bornholdt, Michael and Rajwa, Bartek and Carpenter, Anne E. and Way, Gregory P. and Singh, Shantanu},
  year = {2024},
  month = apr,
  journal = {bioRxiv},
  pages = {2024.04.01.587631},
  doi = {10.1101/2024.04.01.587631},
  urldate = {2024-06-06},
  abstract = {In profiling assays, thousands of biological properties are measured in a single test, yielding biological discoveries by capturing the state of a cell population, often at the single-cell level. However, for profiling datasets, it has been challenging to evaluate the phenotypic activity of a sample and the phenotypic consistency among samples, due to profiles' high dimensionality, heterogeneous nature, and non-linear properties. Existing methods leave researchers uncertain where to draw boundaries between meaningful biological response and technical noise. Here, we developed a statistical framework that uses the well-established mean average precision (mAP) as a single, data-driven metric to bridge this gap. We validated the mAP framework against established metrics through simulations and real-world data applications, revealing its ability to capture subtle and meaningful biological differences in cell state. Specifically, we used mAP to assess both phenotypic activity for a given perturbation (or a sample) as well as consistency within groups of perturbations (or samples) across diverse high-dimensional datasets. We evaluated the framework on different profile types (image, protein, and mRNA profiles), perturbation types (CRISPR gene editing, gene overexpression, and small molecules), and profile resolutions (single-cell and bulk). Our open-source software allows this framework to be applied to identify interesting biological phenomena and promising therapeutics from large-scale profiling data.},
  pmcid = {PMC11014546},
  pmid = {38617315},
  file = {/Users/amunozgo/Zotero/storage/27QHNCPB/Kalinin et al. - 2024 - A versatile information retrieval framework for ev.pdf}
}

@inproceedings{khodadadiOptimizedKalmanFilter2015,
  title = {Optimized Kalman Filter Based on Second Momentum and Triple Rectangular for Cell Tracking on Sequential Microscopic Images},
  booktitle = {2015 22nd {{Iranian Conference}} on {{Biomedical Engineering}} ({{ICBME}})},
  author = {Khodadadi, Vahid and Fatemizadeh, Emad and Setarehdan, S. Kamaledin},
  year = {2015},
  month = nov,
  pages = {251--256},
  publisher = {IEEE},
  address = {Tehran, Iran},
  doi = {10.1109/ICBME.2015.7404151},
  urldate = {2024-04-16},
  isbn = {978-1-4673-9351-5}
}

@misc{kimSelfsupervisionAdvancesMorphological2023,
  title = {Self-Supervision Advances Morphological Profiling by Unlocking Powerful Image Representations},
  author = {Kim, Vladislav and Adaloglou, Nikolaos and Osterland, Marc and Morelli, Flavio M. and Zapata, Paula A. Marin},
  year = {2023},
  month = apr,
  primaryclass = {New Results},
  pages = {2023.04.28.538691},
  publisher = {bioRxiv},
  doi = {10.1101/2023.04.28.538691},
  urldate = {2023-09-26},
  abstract = {Morphological profiling is a powerful technology that enables unbiased characterization of cellular states through image-based screening. Inspired by recent progress in self-supervised learning (SSL), we sought to explore the potential benefits of using SSL in this domain and conducted a comprehensive benchmark study of recent SSL methods for learning representations from Cell Painting images without segmentation. We trained DINO, MAE, and SimCLR on subsets of the JUMP-CP consortium data, one of the largest publicly available Cell Painting image sets, and observed improved model performance with larger and more heterogeneous training sets. Our best model (DINO) surpassed the widely used profiling tool CellProfiler by 29\% in mean average precision (mAP) on classifying chemical perturbations and significantly accelerated feature extraction by 50x, at a lower cost. Moreover, DINO outperformed CellProfiler in clustering gene families on an independent gene overexpression dataset. Our findings indicate that SSL methods can improve the efficiency and performance of morphological profiling, offering the potential to expedite drug discovery and reduce compute costs.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/4KNLM2EL/Kim et al. - 2023 - Self-supervision advances morphological profiling .pdf}
}

@article{lamiableRevealingInvisibleCell2023,
  title = {Revealing Invisible Cell Phenotypes with Conditional Generative Modeling},
  author = {Lamiable, Alexis and Champetier, Tiphaine and Leonardi, Francesco and Cohen, Ethan and Sommer, Peter and Hardy, David and Argy, Nicolas and Massougbodji, Achille and Del Nery, Elaine and Cottrell, Gilles and Kwon, Yong-Jun and Genovesio, Auguste},
  year = {2023},
  month = oct,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {6386},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-42124-6},
  urldate = {2024-06-06},
  abstract = {Biological sciences, drug discovery and medicine rely heavily on cell phenotype perturbation and microscope observation. However, most cellular phenotypic changes are subtle and thus hidden from us by natural cell variability: two cells in the same condition already look different. In this study, we show that conditional generative models can be used to transform an image of cells from any one condition to another, thus canceling cell variability. We visually and quantitatively validate that the principle of synthetic cell perturbation works on discernible cases. We then illustrate its effectiveness in displaying otherwise invisible cell phenotypes triggered by blood cells under parasite infection, or by the presence of a disease-causing pathological mutation in differentiated neurons derived from iPSCs, or by low concentration drug treatments. The proposed approach, easy to use and robust, opens the door to more accessible discovery of biological and disease biomarkers.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Biomarkers,Cellular imaging,Image processing,Organelles},
  file = {/Users/amunozgo/Zotero/storage/HPMVJKSR/Lamiable et al. - 2023 - Revealing invisible cell phenotypes with condition.pdf}
}

@article{liuSaccharomycesCerevisiaeHuman2017,
  title = {From {{Saccharomyces}} Cerevisiae to Human: {{The}} Important Gene Co-Expression Modules},
  shorttitle = {From {{Saccharomyces}} Cerevisiae to Human},
  author = {Liu, Wei and Li, Li and Ye, Hua and Chen, Haiwei and Shen, Weibiao and Zhong, Yuexian and Tian, Tian and He, Huaqin},
  year = {2017},
  month = aug,
  journal = {Biomedical Reports},
  volume = {7},
  number = {2},
  pages = {153--158},
  issn = {2049-9434},
  doi = {10.3892/br.2017.941},
  urldate = {2023-11-29},
  abstract = {Network-based systems biology has become an important method for analyzing high-throughput gene expression data and gene function mining. Yeast has long been a popular model organism for biomedical research. In the current study, a weighted gene co-expression network analysis algorithm was applied to construct a gene co-expression network in Saccharomyces cerevisiae. Seventeen stable gene co-expression modules were detected from 2,814 S. cerevisiae microarray data. Further characterization of these modules with the Database for Annotation, Visualization and Integrated Discovery tool indicated that these modules were associated with certain biological processes, such as heat response, cell cycle, translational regulation, mitochondrion oxidative phosphorylation, amino acid metabolism and autophagy. Hub genes were also screened by intra-modular connectivity. Finally, the module conservation was evaluated in a human disease microarray dataset. Functional modules were identified in budding yeast, some of which are associated with patient survival. The current study provided a paradigm for single cell microorganisms and potentially other organisms.},
  pmcid = {PMC5525645},
  pmid = {28804628},
  file = {/Users/amunozgo/Zotero/storage/G2CTBK5L/Liu et al. - 2017 - From Saccharomyces cerevisiae to human The import.pdf}
}

@misc{maierDrugstOnePlugandplay2023,
  title = {Drugst.{{One}} -- {{A}} Plug-and-Play Solution for Online Systems Medicine and Network-Based Drug Repurposing},
  author = {Maier, Andreas and Hartung, Michael and Abovsky, Mark and Adamowicz, Klaudia and Bader, Gary D. and Baier, Sylvie and Blumenthal, David B. and Chen, Jing and Elkjaer, Maria L. and {Garcia-Hernandez}, Carlos and Helmy, Mohamed and Hoffmann, Markus and Jurisica, Igor and Kotlyar, Max and Lazareva, Olga and Levi, Hagai and List, Markus and Lobentanzer, Sebastian and Loscalzo, Joseph and {Malod-Dognin}, Noel and Manz, Quirin and Matschinske, Julian and Mee, Miles and Oubounyt, Mhaned and Pico, Alexander R. and Pillich, Rudolf T. and Poschenrieder, Julian M. and Pratt, Dexter and Pr{\v z}ulj, Nata{\v s}a and Sadegh, Sepideh and {Saez-Rodriguez}, Julio and Sarkar, Suryadipto and Shaked, Gideon and Shamir, Ron and Trummer, Nico and Turhan, Ugur and Wang, Ruisheng and Zolotareva, Olga and Baumbach, Jan},
  year = {2023},
  month = jul,
  number = {arXiv:2305.15453},
  eprint = {2305.15453},
  primaryclass = {q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.15453},
  urldate = {2024-01-11},
  abstract = {In recent decades, the development of new drugs has become increasingly expensive and inefficient, and the molecular mechanisms of most pharmaceuticals remain poorly understood. In response, computational systems and network medicine tools have emerged to identify potential drug repurposing candidates. However, these tools often require complex installation and lack intuitive visual network mining capabilities. To tackle these challenges, we introduce Drugst.One, a platform that assists specialized computational medicine tools in becoming user-friendly, web-based utilities for drug repurposing. With just three lines of code, Drugst.One turns any systems biology software into an interactive web tool for modeling and analyzing complex protein-drug-disease networks. Demonstrating its broad adaptability, Drugst.One has been successfully integrated with 21 computational systems medicine tools. Available at https://drugst.one, Drugst.One has significant potential for streamlining the drug discovery process, allowing researchers to focus on essential aspects of pharmaceutical treatment research.},
  archiveprefix = {arxiv},
  keywords = {Quantitative Biology - Quantitative Methods},
  file = {/Users/amunozgo/Zotero/storage/YU3QV4WR/Maier et al. - 2023 - Drugst.One -- A plug-and-play solution for online .pdf;/Users/amunozgo/Zotero/storage/YUMSGRPA/2305.html}
}

@article{MasterMargarita2024,
  title = {{\emph{The }}{{{\emph{Master}}}}{\emph{ and }}{{{\emph{Margarita}}}}},
  year = {2024},
  month = mar,
  journal = {Wikipedia},
  urldate = {2024-03-28},
  abstract = {The Master and Margarita (Russian: {\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrs}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrr} {\cyrchar\cyri} {\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrr}{\cyrchar\cyrg}{\cyrchar\cyra}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrt}{\cyrchar\cyra}) is a novel by Soviet writer Mikhail Bulgakov, written in the Soviet Union between 1928 and 1940. A censored version, with several chapters cut by editors, was published in Moscow magazine in 1966--1967, after the writer's death on March 10, 1940, by his widow Elena Bulgakova (Russian: {\cyrchar\CYRE}{\cyrchar\cyrl}{\cyrchar\cyre}{\cyrchar\cyrn}{\cyrchar\cyra} {\cyrchar\CYRB}{\cyrchar\cyru}{\cyrchar\cyrl}{\cyrchar\cyrg}{\cyrchar\cyra}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyra}). The manuscript was not published as a book until 1967, in Paris. A samizdat version circulated that included parts cut out by official censors, and these were incorporated in a 1969 version published in Frankfurt. The novel has since been published in several languages and editions.  The story concerns a visit by the devil and his entourage to the officially atheistic Soviet Union. The devil, manifested as one Professor Woland, challenges the Soviet citizens' beliefs towards religion and condemns their behavior throughout the book. The Master and Margarita combines supernatural elements with satirical dark comedy and Christian philosophy, defying categorization within a single genre. It exhibits autobiographical elements, but is also dominated by many aspects of fiction. Many critics consider it to be one of the best novels of the 20th century, as well as the foremost of Soviet satires.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1216026102},
  file = {/Users/amunozgo/Zotero/storage/3NTAZ4D4/The_Master_and_Margarita.html}
}

@article{miaoRecentAdvancesPhosphodiesterase2023,
  title = {Recent Advances of {{Phosphodiesterase 4B}} in Cancer},
  author = {Miao, Yu and Peng, Li and Chen, Zhaolin and Hu, Ying and Tao, Liangsong and Yao, Yan and Wu, Yincui and Yang, Dashuai and Xu, Tao},
  year = {2023},
  month = feb,
  journal = {Expert Opinion on Therapeutic Targets},
  volume = {27},
  number = {2},
  pages = {121--132},
  issn = {1744-7631},
  doi = {10.1080/14728222.2023.2183496},
  abstract = {INTRODUCTION: Phosphodiesterase 4B (PDE4B) is a crucial enzyme in the phosphodiesterases (PDEs), acting as a regulator of cyclic adenosine monophosphate (cAMP). It is involved in cancer process through PDE4B/cAMP signaling pathway. Cancer occurs and develops with the regulation of PDE4B in the body, suggesting that PDE4B is a promising therapeutic target. AREAS COVERED: This review covereed the function and mechanism of PDE4B in cancer. We summarized the possible clinical applications of PDE4B, and highlighted the possible ways to develop clinical applications of PDE4B inhibitors. We also discussed some common PDEs inhibitors, and expected the development of combined targeting PDE4B and other PDEs drugs in the future. EXPERT OPINION: The existing research and clinical data can strongly prove the role of PDE4B in cancer. PDE4B inhibition can effectively increase cell apoptosis, inhibit cell proliferation, transformation, migration, etc., indicating that PDE4B inhibition can effectively inhibit the development of cancer. Other PDEs may antagonize or coordinate this effect. As for the further study on the relationship between PDE4B and other PDEs in cancer, it is still a challenge to develop multi-targeted PDEs inhibitors.},
  langid = {english},
  pmid = {36803246},
  keywords = {Apoptosis,Cancer,cyclic adenosine monophosphate,Cyclic Nucleotide Phosphodiesterases Type 4,Humans,inhibitors,Neoplasms,phosphodiesterase 4B,phosphodiesterases,Signal Transduction}
}

@inproceedings{narayanaswamyScientificDiscoveryGenerating2020,
  title = {Scientific {{Discovery}} by {{Generating Counterfactuals Using Image Translation}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} -- {{MICCAI}} 2020},
  author = {Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Webster, Dale R. and Peng, Lily and Corrado, Greg S. and Ruamviboonsuk, Paisan and Bavishi, Pinal and Brenner, Michael and Nelson, Philip C. and Varadarajan, Avinash V.},
  editor = {Martel, Anne L. and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A. and Zhou, S. Kevin and Racoceanu, Daniel and Joskowicz, Leo},
  year = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {273--283},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-59710-8_27},
  abstract = {Model explanation techniques play a critical role in understanding the source of a model's performance and making its decisions transparent. Here we investigate if explanation techniques can also be used as a mechanism for scientific discovery. We make three contributions: first, we propose a framework to convert predictions from explanation techniques to a mechanism of discovery. Second, we show how generative models in combination with black-box predictors can be used to generate hypotheses (without human priors) that can be critically examined. Third, with these techniques we study classification models for retinal images predicting Diabetic Macular Edema (DME), where recent work~[30] showed that a CNN trained on these images is likely learning novel features in the image. We demonstrate that the proposed framework is able to explain the underlying scientific mechanism, thus bridging the gap between the model's performance and human understanding.},
  isbn = {978-3-030-59710-8},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/VNSGSUX2/Narayanaswamy et al. - 2020 - Scientific Discovery by Generating Counterfactuals.pdf}
}

@article{neumannPhenotypicProfilingHuman2010,
  title = {Phenotypic Profiling of the Human Genome by Time-Lapse Microscopy Reveals Cell Division Genes},
  author = {Neumann, Beate and Walter, Thomas and H{\'e}rich{\'e}, Jean-Karim and Bulkescher, Jutta and Erfle, Holger and Conrad, Christian and Rogers, Phill and Poser, Ina and Held, Michael and Liebel, Urban and Cetin, Cihan and Sieckmann, Frank and Pau, Gregoire and Kabbe, Rolf and W{\"u}nsche, Annelie and Satagopam, Venkata and Schmitz, Michael H. A. and Chapuis, Catherine and Gerlich, Daniel W. and Schneider, Reinhard and Eils, Roland and Huber, Wolfgang and Peters, Jan-Michael and Hyman, Anthony A. and Durbin, Richard and Pepperkok, Rainer and Ellenberg, Jan},
  year = {2010},
  month = apr,
  journal = {Nature},
  volume = {464},
  number = {7289},
  pages = {721--727},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature08869},
  urldate = {2024-02-08},
  abstract = {Despite our rapidly growing knowledge about the human genome, we do not know all of the genes required for some of the most basic functions of life. To start to fill this gap we developed a high-throughput phenotypic screening platform combining potent gene silencing by RNA interference, time-lapse microscopy and computational image processing. We carried out a genome-wide phenotypic profiling of each of the {$\sim$}21,000 human protein-coding genes by two-day live imaging of fluorescently labelled chromosomes. Phenotypes were scored quantitatively by computational image processing, which allowed us to identify hundreds of human genes involved in diverse biological functions including cell division, migration and survival. As part of the Mitocheck consortium, this study provides an in-depth analysis of cell division phenotypes and makes the entire high-content data set available as a resource to the community.},
  copyright = {2010 Macmillan Publishers Limited. All rights reserved},
  langid = {english},
  keywords = {Cell division,Genetic association study,Time-lapse imaging},
  file = {/Users/amunozgo/Zotero/storage/QJMVPD2Z/Neumann et al. - 2010 - Phenotypic profiling of the human genome by time-l.pdf}
}

@misc{ovadiaCanYouTrust2019,
  title = {Can {{You Trust Your Model}}'s {{Uncertainty}}? {{Evaluating Predictive Uncertainty Under Dataset Shift}}},
  shorttitle = {Can {{You Trust Your Model}}'s {{Uncertainty}}?},
  author = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D. and Nowozin, Sebastian and Dillon, Joshua V. and Lakshminarayanan, Balaji and Snoek, Jasper},
  year = {2019},
  month = dec,
  number = {arXiv:1906.02530},
  eprint = {1906.02530},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-03-13},
  abstract = {Modern machine learning methods including deep learning have achieved great success in predictive accuracy for supervised learning tasks, but may still fall short in giving useful estimates of their predictive uncertainty. Quantifying uncertainty is especially critical in real-world settings, which often involve input distributions that are shifted from the training distribution due to a variety of factors including sample bias and non-stationarity. In such settings, well calibrated uncertainty estimates convey information about when a model's output should (or should not) be trusted. Many probabilistic deep learning methods, including Bayesian-and nonBayesian methods, have been proposed in the literature for quantifying predictive uncertainty, but to our knowledge there has not previously been a rigorous largescale empirical comparison of these methods under dataset shift. We present a largescale benchmark of existing state-of-the-art methods on classification problems and investigate the effect of dataset shift on accuracy and calibration. We find that traditional post-hoc calibration does indeed fall short, as do several other previous methods. However, some methods that marginalize over models give surprisingly strong results across a broad spectrum of tasks.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/amunozgo/Zotero/storage/DP3DVN4A/Ovadia et al. - 2019 - Can You Trust Your Model's Uncertainty Evaluating.pdf}
}

@article{plazaAnalyzingImageSegmentation2018,
  title = {Analyzing {{Image Segmentation}} for {{Connectomics}}},
  author = {Plaza, Stephen M. and Funke, Jan},
  year = {2018},
  month = nov,
  journal = {Frontiers in Neural Circuits},
  volume = {12},
  pages = {102},
  issn = {1662-5110},
  doi = {10.3389/fncir.2018.00102},
  urldate = {2023-08-11},
  file = {/Users/amunozgo/Zotero/storage/BK5BYTQU/Plaza and Funke - 2018 - Analyzing Image Segmentation for Connectomics.pdf}
}

@article{plazaAnalyzingImageSegmentation2018a,
  title = {Analyzing {{Image Segmentation}} for {{Connectomics}}},
  author = {Plaza, Stephen M. and Funke, Jan},
  year = {2018},
  month = nov,
  journal = {Frontiers in Neural Circuits},
  volume = {12},
  pages = {102},
  issn = {1662-5110},
  doi = {10.3389/fncir.2018.00102},
  urldate = {2023-08-11},
  file = {/Users/amunozgo/Zotero/storage/KPHCN9YB/Plaza and Funke - 2018 - Analyzing Image Segmentation for Connectomics.pdf}
}

@misc{PredictiveMaintenanceInternet,
  title = {Predictive {{Maintenance}} in the {{Internet}} of {{Things}}: {{Survival Analysis}} and {{Deep Learning}} on {{Time Series Data}} from a {{Large Scale Wireless Sensor Network}} - {{ProQuest}}},
  shorttitle = {Predictive {{Maintenance}} in the {{Internet}} of {{Things}}},
  urldate = {2023-11-01},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
  howpublished = {https://www.proquest.com/openview/5839cc07c19dda58edbb5c12a6efe2ed/1?pq-origsite=gscholar\&cbl=18750\&diss=y},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/V87ZKYDI/1.html}
}

@article{renSupervisedLearningHighconfidence,
  title = {Supervised Learning of High-Confidence Phenotypic Subpopulations from Single-Cell Data},
  author = {Ren, Tao and Chen, Canping and Danilov, Alexey V and Liu, Susan and Guan, Xiangnan and Wu, Xiwei and Sherman, Mara H and Spellman, Paul T and Coussens, Lisa M and Mills, Gordon B and Wu, Ling-Yun and Xia, Zheng},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/XGA7URR8/Ren et al. - Supervised learning of high-confidence phenotypic .pdf}
}

@misc{renSupervisedLearningHighconfidence2023,
  title = {Supervised Learning of High-Confidence Phenotypic Subpopulations from Single-Cell Data},
  author = {Ren, Tao and Chen, Canping and Danilov, Alexey V. and Liu, Susan and Guan, Xiangnan and Du, Shunyi and Wu, Xiwei and Sherman, Mara H. and Spellman, Paul T. and Coussens, Lisa M. and Adey, Andrew C. and Mills, Gordon B. and Wu, Ling-Yun and Xia, Zheng},
  year = {2023},
  month = mar,
  primaryclass = {New Results},
  pages = {2023.03.23.533712},
  publisher = {bioRxiv},
  doi = {10.1101/2023.03.23.533712},
  urldate = {2023-08-16},
  abstract = {Accurately identifying phenotype-relevant cell subsets from heterogeneous cell populations is crucial for delineating the underlying mechanisms driving biological or clinical phenotypes. Here, by deploying a learning with rejection strategy, we developed a novel supervised learning framework called PENCIL to identify subpopulations associated with categorical or continuous phenotypes from single-cell data. By embedding a feature selection function into this flexible framework, for the first time, we were able to select informative features and identify cell subpopulations simultaneously, which enables the accurate identification of phenotypic subpopulations otherwise missed by methods incapable of concurrent gene selection. Furthermore, the regression mode of PENCIL presents a novel ability for supervised phenotypic trajectory learning of subpopulations from single-cell data. We conducted comprehensive simulations to evaluate PENCIL's versatility in simultaneous gene selection, subpopulation identification and phenotypic trajectory prediction. PENCIL is fast and scalable to analyze 1 million cells within 1 hour. Using the classification mode, PENCIL detected T-cell subpopulations associated with melanoma immunotherapy outcomes. Moreover, when applied to scRNA-seq of a mantle cell lymphoma patient with drug treatment across multiple time points, the regression mode of PENCIL revealed a transcriptional treatment response trajectory. Collectively, our work introduces a scalable and flexible infrastructure to accurately identify phenotype-associated subpopulations from single-cell data.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/CCK9ULTU/Ren et al. - 2023 - Supervised learning of high-confidence phenotypic .pdf}
}

@techreport{sealPixelsPhenotypesIntegrating2023,
  type = {Preprint},
  title = {From {{Pixels}} to {{Phenotypes}}: {{Integrating Image-Based Profiling}} with {{Cell Health Data Improves Interpretability}}},
  shorttitle = {From {{Pixels}} to {{Phenotypes}}},
  author = {Seal, Srijit and {Carreras-Puigvert}, Jordi and Carpenter, Anne E and Spjuth, Ola and Bender, Andreas},
  year = {2023},
  month = jul,
  institution = {Cell Biology},
  doi = {10.1101/2023.07.14.549031},
  urldate = {2023-08-17},
  abstract = {Cell Painting assays generate morphological profiles that are versatile descriptors of biological systems and have been used to predict in vitro and in vivo drug effects. However, Cell Painting features are based on image statistics, and are, therefore, often not readily biologically interpretable. In this study, we introduce an approach that maps specific Cell Painting features into the BioMorph space using readouts from comprehensive Cell Health assays. We validated that the resulting BioMorph space effectively connected compounds not only with the morphological features associated with their bioactivity but with deeper insights into phenotypic characteristics and cellular processes associated with the given bioactivity. The BioMorph space revealed the mechanism of action for individual compounds, including dual-acting compounds such as emetine, an inhibitor of both protein synthesis and DNA replication. In summary, BioMorph space offers a more biologically relevant way to interpret cell morphological features from the Cell Painting assays and to generate hypotheses for experimental validation.},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/3DZYKUDS/Seal et al. - 2023 - From Pixels to Phenotypes Integrating Image-Based.pdf}
}

@misc{sivanandanPooledCellPainting2023,
  title = {A {{Pooled Cell Painting CRISPR Screening Platform Enables}} de Novo {{Inference}} of {{Gene Function}} by {{Self-supervised Deep Learning}}},
  author = {Sivanandan, Srinivasan and Leitmann, Bobby and Lubeck, Eric and Sultan, Mohammad Muneeb and Stanitsas, Panagiotis and Ranu, Navpreet and Ewer, Alexis and Mancuso, Jordan E. and Phillips, Zachary F. and Kim, Albert and Bisognano, John W. and Cesarek, John and Ruggiu, Fiorella and Feldman, David and Koller, Daphne and Sharon, Eilon and Kaykas, Ajamete and Salick, Max R. and Chu, Ci},
  year = {2023},
  month = aug,
  primaryclass = {New Results},
  pages = {2023.08.13.553051},
  publisher = {bioRxiv},
  doi = {10.1101/2023.08.13.553051},
  urldate = {2023-09-26},
  abstract = {Pooled CRISPR screening has emerged as a powerful method of mapping gene functions thanks to its scalability, affordability, and robustness against well or plate-specific confounders present in array-based screening 1--6. Most pooled CRISPR screens assay for low dimensional phenotypes (e.g. fitness, fluorescent markers). Higher-dimensional assays such as perturb-seq are available but costly and only applicable to transcriptomics readouts 7--11. Recently, pooled optical screening, which combines pooled CRISPR screening and microscopy-based assays, has been demonstrated in the studies of the NFkB pathway, essential human genes, cytoskeletal organization and antiviral response 12--15. While the pooled optical screening methodology is scalable and information-rich, the applications thus far employ hypothesis-specific assays. Here, we enable hypothesis-free reverse genetic screening for generic morphological phenotypes by re-engineering the Cell Painting 16 technique to provide compatibility with pooled optical screening. We validated this technique using well-defined morphological genesets (124 genes), compared classical image analysis and self-supervised learning methods using a mechanism-of-action (MoA) library (300 genes), and performed discovery screening with a druggable genome library (1640 genes) 17. Across these three experiments we show that the combination of rich morphological data and deep learning allows gene networks to emerge without the need for target-specific biomarkers, leading to better discovery of gene functions.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/FWF4NVJA/Sivanandan et al. - 2023 - A Pooled Cell Painting CRISPR Screening Platform E.pdf}
}

@article{stringerCellposeGeneralistAlgorithm2021,
  title = {Cellpose: A Generalist Algorithm for Cellular Segmentation},
  shorttitle = {Cellpose},
  author = {Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
  year = {2021},
  month = jan,
  journal = {Nature Methods},
  volume = {18},
  number = {1},
  pages = {100--106},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-020-01018-x},
  urldate = {2023-08-30},
  abstract = {Many biological applications require the segmentation of cell bodies, membranes and nuclei from microscopy images. Deep learning has enabled great progress on this problem, but current methods are specialized for images that have large training datasets. Here we introduce a generalist, deep learning-based segmentation method called Cellpose, which can precisely segment cells from a wide range of image types and does not require model retraining or parameter adjustments. Cellpose was trained on a new dataset of highly varied images of cells, containing over 70,000 segmented objects. We also demonstrate a three-dimensional (3D) extension of Cellpose that reuses the two-dimensional (2D) model and does not require 3D-labeled data. To support community contributions to the training data, we developed software for manual labeling and for curation of the automated results. Periodically retraining the model on the community-contributed data will ensure that Cellpose improves constantly. Cellpose is a generalist, deep learning-based approach for segmenting structures in a wide range of image types. Cellpose does not require parameter adjustment or model retraining and outperforms established methods on 2D and 3D datasets.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Cell biology,Computational biology and bioinformatics},
  file = {/Users/amunozgo/Zotero/storage/YJUMVDM9/Stringer et al. - 2021 - Cellpose a generalist algorithm for cellular segm.pdf}
}

@misc{sunRealDifferencesOT2020,
  title = {Real {{Differences}} between {{OT}} and {{CRDT}} under a {{General Transformation Framework}} for {{Consistency Maintenance}} in {{Co-Editors}}},
  author = {Sun, Chengzheng and Sun, David and Agustina and Cai, Weiwei},
  year = {2020},
  month = jun,
  number = {arXiv:1905.01518},
  eprint = {1905.01518},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1905.01518},
  urldate = {2023-10-18},
  abstract = {OT (Operational Transformation) was invented for supporting real-time co-editors in the late 1980s and has evolved to become a core technique used in today's working co-editors and adopted in major industrial products. CRDT (Commutative Replicated Data Type) for co-editors was first proposed around 2006, under the name of WOOT (WithOut Operational Transformation). Follow-up CRDT variations are commonly labeled as "post-OT" techniques capable of making concurrent operations natively commutative in co-editors. On top of that, CRDT solutions have made broad claims of superiority over OT solutions, and routinely portrayed OT as an incorrect, complex and inefficient technique. Over one decade later, however, OT remains the choice for building the vast majority of co-editors, whereas CRDT is rarely found in working co-editors. Contradictions between the reality and CRDT's purported advantages have been the source of much confusion and debate in co-editing communities. Have the vast majority of co-editors been unfortunate in choosing the faulty and inferior OT, or those CRDT claims are false? What are the real differences between OT and CRDT for co-editors? What are the key factors and underlying reasons behind the choices between OT and CRDT in the real world? To seek truth from facts, we set out to conduct a comprehensive and critical review on representative OT and CRDT solutions and working co-editors based on them. From this work, we have made important discoveries about OT and CRDT, and revealed facts and evidences that refute CRDT claims over OT on all accounts. We report our discoveries in a series of three articles and the current article is the first one in this series. We hope the discoveries from this work help clear up common misconceptions and confusions surrounding OT and CRDT, and accelerate progress in co-editing technology for real world applications.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Human-Computer Interaction,Computer Science - Software Engineering},
  file = {/Users/amunozgo/Zotero/storage/WRDG4ZRV/Sun et al. - 2020 - Real Differences between OT and CRDT under a Gener.pdf;/Users/amunozgo/Zotero/storage/HNE46GHS/1905.html}
}

@incollection{swinneyChapter18Molecular2011,
  title = {Chapter 18 - {{Molecular Mechanism}} of {{Action}} ({{MMoA}}) in {{Drug Discovery}}},
  booktitle = {Annual {{Reports}} in {{Medicinal Chemistry}}},
  author = {Swinney, David C.},
  editor = {Macor, John E.},
  year = {2011},
  month = jan,
  volume = {46},
  pages = {301--317},
  publisher = {Academic Press},
  doi = {10.1016/B978-0-12-386009-5.00009-6},
  urldate = {2023-08-24},
  abstract = {This chapter focuses on the molecular mechanism of action (MMoA) in drug discovery. MMoA of a medicine is the connection of the molecular interactions between the therapeutic treatment and the biological target that yields the physiological response. Mechanism-based toxicity is a potential concern with most human targets. MMoAs provide the means to minimize the mechanism-based toxicity while retaining the desired response. Competition with endogenous effectors, uncompetitive inhibition, partial agonism, functional selectivity, and allosteric partial antagonism are mechanisms in which the physiological environment can help to shape the dose--response curves to minimize mechanism-based toxicity while retaining sufficient drug efficacy. Fast kinetics can minimize mechanism-based toxicity by enabling equilibrium competition that may be advantageous if sufficient efficacy can be maintained. This is exemplified by a number of medicines including atypical antipsychotics working through the D2 receptor, nonsteroidal anti-inflammatory drugs, such as ibuprofen, and N-methyl-D-aspartate antagonists. A challenge for medicinal chemists is that many of the molecular interactions that contribute to binding kinetics and MMoA are dynamic, involving structural movements and conformational rearrangements. Some insights are provided by studies with influenza B neuraminidase, which reveals rotations in residues important for binding, and the enoyl-acyl carrier protein (ACP) reductase of Mycobacterium tuberculosis (InhA), which shows a loop ordering involved in the slow kinetics.},
  keywords = {Agonist,Antagonist,Binding kinetics,Mechanism-based toxicity,Molecular mechanism of action},
  file = {/Users/amunozgo/Zotero/storage/JX9E5WFL/B9780123860095000096.html}
}

@inproceedings{tonksEvaluatingVirtualStaining2023,
  title = {Evaluating Virtual Staining for High-Throughput Screening},
  booktitle = {2023 {{IEEE}} 20th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  author = {Tonks, Samuel and Hsu, Chih-Yang and Hood, Steve and Musso, Ryan and Hopely, Ceridwen and Titus, Steve and Krull, Alexander and Doan, Minh and Styles, Iain},
  year = {2023},
  month = apr,
  pages = {1--5},
  publisher = {IEEE},
  address = {Cartagena, Colombia},
  doi = {10.1109/ISBI53787.2023.10230501},
  urldate = {2024-01-17},
  abstract = {Little is known about the feasibility of virtual staining for industry applications such as high-throughput screening (HTS). We provide a thorough analysis of the usability of image-toimage translation for the virtual staining of label-free brightfield microscopy images of live cells, using a pool of more than 1.6 million images across six lung, six ovarian and six breast cell lines consisting of paired bright-field, cytoplasm, nuclei and DNA-damage stains. To our knowledge this is the first time an analysis of virtual staining has been performed on three levels; pixel-based, biological-feature based, and determining if virtual staining can reproduce drug-effect. Our results reveal that while virtually stained nuclei and cytoplasm images often consistently and faithfully reproduce the information found in fluorescence microscopy, virtually stained images of DNA-damage are usually less accurate.},
  isbn = {978-1-66547-358-3},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/5IQQ99GX/Tonks et al. - 2023 - Evaluating virtual staining for high-throughput sc.pdf}
}

@inproceedings{tschoppEfficientConvolutionalNeural2016,
  title = {Efficient Convolutional Neural Networks for Pixelwise Classification on Heterogeneous Hardware Systems},
  booktitle = {2016 {{IEEE}} 13th {{International Symposium}} on {{Biomedical Imaging}} ({{ISBI}})},
  author = {Tschopp, Fabian and Martel, Julien N. P. and Turaga, Srinivas C. and Cook, Matthew and Funke, Jan},
  year = {2016},
  month = apr,
  pages = {1225--1228},
  publisher = {IEEE},
  address = {Prague, Czech Republic},
  doi = {10.1109/ISBI.2016.7493487},
  urldate = {2023-08-11},
  isbn = {978-1-4799-2349-6},
  file = {/Users/amunozgo/Zotero/storage/MX8XME9B/Tschopp et al. - 2016 - Efficient convolutional neural networks for pixelw.pdf}
}

@misc{UniversalPeriodicoMexico2024,
  title = {{El Universal {\textbar} El peri{\'o}dico de M{\'e}xico l{\'i}der en noticias y clasificados}},
  year = {2024},
  month = apr,
  journal = {El Universal},
  urldate = {2024-04-08},
  abstract = {Noticias de {\'u}ltima hora de M{\'e}xico y el mundo. Noticias minuto a minuto de pol{\'i}tica, ovidio, culiacan, AMLO, AIFA, Ucrania, Rusia, deportes, espect{\'a}culos,},
  howpublished = {https://www.eluniversal.com.mx/},
  langid = {spanish},
  file = {/Users/amunozgo/Zotero/storage/EIZAYPZ3/www.eluniversal.com.mx.html}
}

@misc{UserBarbacoa,
  title = {User Barbacoa},
  journal = {Emacs Stack Exchange},
  urldate = {2024-04-09},
  howpublished = {https://emacs.stackexchange.com/users/41559/barbacoa},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/CQAX3PCW/barbacoa.html}
}

@article{weiComparisonNeuronalPopulation2020,
  title = {A Comparison of Neuronal Population Dynamics Measured with Calcium Imaging and Electrophysiology},
  author = {Wei, Ziqiang and Lin, Bei-Jung and Chen, Tsai-Wen and Daie, Kayvon and Svoboda, Karel and Druckmann, Shaul},
  editor = {Gutkin, Boris S.},
  year = {2020},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {9},
  pages = {e1008198},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008198},
  urldate = {2023-08-11},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/9LCBKHES/Wei et al. - 2020 - A comparison of neuronal population dynamics measu.pdf}
}

@article{wigginsCellPheToolkitCell2023,
  title = {The {{CellPhe}} Toolkit for Cell Phenotyping Using Time-Lapse Imaging and Pattern Recognition},
  author = {Wiggins, Laura and Lord, Alice and Murphy, Killian L. and Lacy, Stuart E. and O'Toole, Peter J. and Brackenbury, William J. and Wilson, Julie},
  year = {2023},
  month = apr,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {1854},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-37447-3},
  urldate = {2024-04-22},
  abstract = {With phenotypic heterogeneity in whole cell populations widely recognised, the demand for quantitative and temporal analysis approaches to characterise single cell morphology and dynamics has increased. We present CellPhe, a pattern recognition toolkit for the unbiased characterisation of cellular phenotypes within time-lapse videos. CellPhe imports tracking information from multiple segmentation and tracking algorithms to provide automated cell phenotyping from different imaging modalities, including fluorescence. To maximise data quality for downstream analysis, our toolkit includes automated recognition and removal of erroneous cell boundaries induced by inaccurate tracking and segmentation. We provide an extensive list of features extracted from individual cell time series, with custom feature selection to identify variables that provide greatest discrimination for the analysis in question. Using ensemble classification for accurate prediction of cellular phenotype and clustering algorithms for the characterisation of heterogeneous subsets, we validate and prove adaptability using different cell types and experimental conditions.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Cellular imaging,Software},
  file = {/Users/amunozgo/Zotero/storage/NT7XQ2KA/Wiggins et al. - 2023 - The CellPhe toolkit for cell phenotyping using tim.pdf}
}

@misc{wigginsExploringImpactVariability2023,
  title = {Exploring the Impact of Variability in Cell Segmentation and Tracking Approaches},
  author = {Wiggins, Laura and O'Toole, Peter J. and Brackenbury, William J. and Wilson, Julie},
  year = {2023},
  month = nov,
  primaryclass = {New Results},
  pages = {2023.11.24.568598},
  publisher = {bioRxiv},
  doi = {10.1101/2023.11.24.568598},
  urldate = {2024-04-22},
  abstract = {Segmentation and tracking are essential preliminary steps in the analysis of almost all live cell imaging applications. Although the number of open-source software systems that facilitate automated segmentation and tracking continue to evolve, many researchers continue to opt for manual alternatives for samples that are not easily auto-segmented, tracing cell boundaries by hand and re-identifying cells on consecutive frames by eye. Such methods are subject to inter-user variability, introducing idiosyncrasies into the results of downstream analysis that are a result of subjectivity and individual expertise. Such methods are also susceptible to intra-user variability, meaning findings are challenging to reproduce. Here we demonstrate and quantify the degree of intra- and inter-user variability in manual cell segmentation and tracking by comparing the phenotypic metrics extracted from cells segmented and tracked by different members of our research team. Furthermore, we compare the segmentation results for a ptychographic cell image obtained using different automated software and demonstrate the high dependence of performance on their imaging modality optimisation. Our results show that choice of segmentation and tracking methods should be considered carefully in order to enhance the quality and reproducibility of results.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/amunozgo/Zotero/storage/9GSWFH6I/Wiggins et al. - 2023 - Exploring the impact of variability in cell segmen.pdf}
}

@inproceedings{zhuUnpairedImageToImageTranslation2017,
  title = {Unpaired {{Image-To-Image Translation Using Cycle-Consistent Adversarial Networks}}},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  year = {2017},
  pages = {2223--2232},
  urldate = {2023-08-21},
  file = {/Users/amunozgo/Zotero/storage/5IMT3QCZ/Zhu et al. - 2017 - Unpaired Image-To-Image Translation Using Cycle-Co.pdf}
}

@article{zotero-110,
  type = {Article}
}

@misc{zotero-127,
  type = {Misc}
}
